<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CSCE 645 Final Report - High-Fidelity Mesh Smoothing for Medical Brain MRI Data</title>
    <meta name="description" content="Comprehensive evaluation of semantic-aware mesh smoothing algorithms for medical imaging with volume preservation guarantees exceeding FDA requirements.">
    <meta name="author" content="Shubham Vikas Mhaske">
    <meta name="keywords" content="mesh smoothing, medical imaging, brain MRI, volume preservation, Laplacian smoothing, Taubin smoothing, geometric modeling">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;500;600;700;800&family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&family=Source+Serif+4:opsz,wght@8..60,400;8..60,500;8..60,600&display=swap" rel="stylesheet">
    
    <!-- KaTeX for Math -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>
    
    <!-- Prism.js for Code Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-python.min.js"></script>
    <style>
        :root {
            --maroon: #500000;
            --maroon-dark: #3c0000;
            --gold: #998542;
            --gold-light: #d4af37;
            --cream: #faf9f6;
            --text: #2d2d2d;
            --text-light: #5a5a5a;
            --border: #e8e4e0;
            --shadow: rgba(80, 0, 0, 0.08);
            --gradient-start: #500000;
            --gradient-end: #2c0000;
            --success: #1a7f37;
            --success-bg: #e6f4ea;
            --warning: #9a6700;
            --warning-bg: #fff8e6;
            --danger: #cf222e;
            --danger-bg: #ffebe9;
            --info: #0969da;
            --info-bg: #ddf4ff;
        }
        
        * { box-sizing: border-box; margin: 0; padding: 0; }
        
        html { scroll-behavior: smooth; }
        
        body {
            font-family: 'Source Serif 4', 'Inter', -apple-system, BlinkMacSystemFont, serif;
            line-height: 1.9;
            color: var(--text);
            background: linear-gradient(180deg, var(--cream) 0%, #fff 100%);
            font-size: 17px;
            -webkit-font-smoothing: antialiased;
            text-rendering: optimizeLegibility;
        }
        
        /* Print Styles */
        @media print {
            body { background: white; font-size: 11pt; }
            header { background: var(--maroon) !important; padding: 40px 20px; }
            .container { max-width: 100%; padding: 20px; }
            .toc, .abstract { box-shadow: none; border: 1px solid #ddd; }
            figure img { max-width: 100%; page-break-inside: avoid; }
            section { page-break-inside: avoid; }
            .no-print { display: none !important; }
        }
        
        /* Header */
        header {
            background: linear-gradient(135deg, var(--gradient-start) 0%, var(--gradient-end) 100%);
            color: white;
            padding: 100px 40px 90px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }
        
        header::before {
            content: '';
            position: absolute;
            top: 0; left: 0; right: 0; bottom: 0;
            background: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%23ffffff' fill-opacity='0.03'%3E%3Cpath d='M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
            opacity: 0.5;
        }
        
        header::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 6px;
            background: linear-gradient(90deg, var(--gold) 0%, var(--gold-light) 50%, var(--gold) 100%);
        }
        
        .header-badge {
            display: inline-block;
            background: rgba(255,255,255,0.15);
            padding: 8px 20px;
            border-radius: 30px;
            font-size: 0.85em;
            font-weight: 500;
            letter-spacing: 1.5px;
            text-transform: uppercase;
            margin-bottom: 25px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
        }
        
        header h1 {
            font-family: 'Playfair Display', Georgia, serif;
            font-size: 2.8em;
            font-weight: 700;
            margin-bottom: 20px;
            line-height: 1.2;
            position: relative;
            text-shadow: 0 2px 4px rgba(0,0,0,0.2);
            max-width: 900px;
            margin-left: auto;
            margin-right: auto;
        }
        
        header .subtitle {
            font-family: 'Inter', sans-serif;
            font-size: 1.3em;
            font-weight: 400;
            opacity: 0.95;
            margin-bottom: 30px;
            letter-spacing: 0.3px;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
        }
        
        header .meta {
            display: flex;
            justify-content: center;
            gap: 50px;
            flex-wrap: wrap;
            font-size: 0.95em;
            opacity: 0.95;
            font-family: 'Inter', sans-serif;
        }
        
        header .meta-item {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        header .meta-item svg {
            width: 20px;
            height: 20px;
            opacity: 0.9;
        }
        
        header .meta-item a {
            color: var(--gold-light);
            text-decoration: none;
            transition: color 0.2s;
        }
        
        header .meta-item a:hover {
            color: white;
            text-decoration: underline;
        }

        header .viewing-note {
            margin-top: 22px;
            font-family: 'Inter', sans-serif;
            font-size: 0.95em;
            max-width: 860px;
            margin-left: auto;
            margin-right: auto;
            color: rgba(255, 255, 255, 0.95);
            line-height: 1.5;
        }

        header .viewing-note strong {
            color: white;
        }
        
        /* Container */
        .container {
            max-width: 920px;
            margin: 0 auto;
            padding: 50px 40px;
        }
        
        /* Abstract */
        .abstract {
            background: white;
            padding: 35px 40px;
            border-radius: 12px;
            box-shadow: 0 4px 20px var(--shadow);
            margin: -40px 40px 50px;
            position: relative;
            border-left: 5px solid var(--gold);
        }
        
        .abstract h3 {
            font-family: 'Playfair Display', serif;
            font-size: 1.4em;
            color: var(--maroon);
            margin-bottom: 15px;
        }
        
        .abstract p {
            color: var(--text-light);
            font-size: 1.02em;
            line-height: 1.9;
        }
        
        /* Table of Contents */
        .toc {
            background: white;
            border-radius: 12px;
            padding: 30px 35px;
            margin-bottom: 50px;
            box-shadow: 0 2px 15px var(--shadow);
        }
        
        .toc h2 {
            font-family: 'Playfair Display', serif;
            font-size: 1.3em;
            color: var(--maroon);
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .toc ol {
            list-style: none;
            counter-reset: toc;
            margin: 0;
            padding: 0;
        }
        
        .toc > ol > li {
            counter-increment: toc;
            margin: 12px 0;
        }
        
        .toc > ol > li > a::before {
            content: counter(toc) ".";
            color: var(--gold);
            font-weight: 600;
            margin-right: 10px;
        }
        
        .toc a {
            color: var(--text);
            text-decoration: none;
            transition: color 0.2s;
        }
        
        .toc a:hover {
            color: var(--maroon);
        }
        
        .toc ol ol {
            margin-left: 30px;
            margin-top: 8px;
        }
        
        .toc ol ol li {
            margin: 6px 0;
            font-size: 0.95em;
            color: var(--text-light);
        }
        
        /* Sections */
        section {
            margin-bottom: 60px;
        }
        
        h2.section-title {
            font-family: 'Playfair Display', serif;
            font-size: 2em;
            color: var(--maroon);
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid var(--gold);
            display: flex;
            align-items: center;
            gap: 15px;
        }
        
        h2.section-title .section-number {
            background: var(--maroon);
            color: white;
            width: 45px;
            height: 45px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.7em;
            font-family: 'Inter', sans-serif;
            font-weight: 600;
        }
        
        h3 {
            font-family: 'Playfair Display', serif;
            font-size: 1.45em;
            color: var(--maroon-dark);
            margin: 35px 0 18px;
        }
        
        h4 {
            font-size: 1.15em;
            font-weight: 600;
            color: var(--text);
            margin: 28px 0 14px;
        }
        
        p {
            margin-bottom: 18px;
            text-align: justify;
            hyphens: auto;
        }
        
        /* Lists */
        ul, ol {
            margin: 18px 0 18px 25px;
        }
        
        li {
            margin: 10px 0;
            padding-left: 5px;
        }
        
        li::marker {
            color: var(--gold);
        }
        
        /* Figures */
        figure {
            margin: 35px 0;
            text-align: center;
        }
        
        figure img {
            max-width: 100%;
            border-radius: 10px;
            box-shadow: 0 4px 25px var(--shadow);
        }
        
        figcaption {
            font-size: 0.92em;
            color: var(--text-light);
            margin-top: 15px;
            font-style: italic;
            max-width: 85%;
            margin-left: auto;
            margin-right: auto;
        }
        
        /* Equations */
        .equation-block {
            background: linear-gradient(135deg, #fdfcfb 0%, #f8f6f3 100%);
            padding: 25px 30px;
            margin: 25px 0;
            border-radius: 10px;
            border: 1px solid var(--border);
            overflow-x: auto;
            text-align: center;
            position: relative;
        }
        
        .equation-block .eq-number {
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: var(--text-light);
            font-size: 0.9em;
        }
        
        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.95em;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 2px 15px var(--shadow);
        }
        
        th, td {
            padding: 14px 18px;
            text-align: left;
        }
        
        th {
            background: linear-gradient(135deg, var(--maroon) 0%, var(--maroon-dark) 100%);
            color: white;
            font-weight: 600;
            font-size: 0.92em;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        tr:nth-child(even) {
            background: var(--cream);
        }
        
        tr:hover {
            background: #f5f3f0;
        }
        
        td {
            border-bottom: 1px solid var(--border);
        }
        
        .best-value {
            font-weight: 600;
            color: #1a7f37;
            background: #e6f4ea;
            padding: 3px 8px;
            border-radius: 4px;
        }
        
        .highlight {
            font-weight: 700;
            color: #0969da;
            background: #ddf4ff;
            padding: 3px 8px;
            border-radius: 4px;
        }
        
        .warning {
            font-weight: 700;
            color: #d1242f;
            background: #ffebe9;
            padding: 3px 8px;
            border-radius: 4px;
        }
        
        .baseline-row {
            background: #f0f6ff !important;
        }
        
        .novel-row {
            background: #fff8e1 !important;
        }
        
        .highlight-row {
            background: #e6f4ea !important;
            font-weight: 600;
        }
        
        .status-excellent {
            color: #1a7f37;
            font-weight: 600;
        }
        
        .status-good {
            color: #0969da;
            font-weight: 600;
        }
        
        .status-warning {
            color: #d1242f;
            font-weight: 600;
        }
        
        /* Algorithm Boxes */
        .algorithm-card {
            background: white;
            border-radius: 12px;
            margin: 30px 0;
            overflow: hidden;
            box-shadow: 0 4px 20px var(--shadow);
            border: 1px solid var(--border);
        }
        
        .algorithm-card .card-header {
            background: linear-gradient(135deg, var(--maroon) 0%, var(--maroon-dark) 100%);
            color: white;
            padding: 18px 25px;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }
        
        .algorithm-card .card-header h4 {
            margin: 0;
            color: white;
            font-family: 'Playfair Display', serif;
            font-size: 1.2em;
        }
        
        .algorithm-card .contribution-badge {
            background: var(--gold);
            color: white;
            padding: 5px 14px;
            border-radius: 20px;
            font-size: 0.75em;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .algorithm-card .card-body {
            padding: 25px;
        }
        
        .algorithm-steps {
            background: var(--cream);
            border-radius: 8px;
            padding: 20px 25px;
            margin: 20px 0;
        }
        
        .algorithm-steps ol {
            margin: 0;
            padding-left: 20px;
        }
        
        /* Code blocks */
        pre {
            background: #1e1e2e;
            color: #cdd6f4;
            padding: 20px 25px;
            border-radius: 10px;
            overflow-x: auto;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.88em;
            line-height: 1.6;
            margin: 20px 0;
        }
        
        code {
            font-family: 'JetBrains Mono', monospace;
            background: #f4f3f1;
            padding: 2px 7px;
            border-radius: 4px;
            font-size: 0.88em;
            color: var(--maroon);
        }
        
        /* Metric Cards */
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .metric-card {
            background: white;
            border-radius: 12px;
            padding: 25px;
            text-align: center;
            box-shadow: 0 3px 15px var(--shadow);
            border: 1px solid var(--border);
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .metric-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 25px var(--shadow);
        }
        
        .metric-card .value {
            font-size: 2.5em;
            font-weight: 700;
            color: var(--maroon);
            line-height: 1.2;
        }
        
        .metric-card .label {
            font-size: 0.9em;
            color: var(--text-light);
            margin-top: 8px;
        }
        
        .metric-card .detail {
            font-size: 0.82em;
            color: var(--gold);
            margin-top: 5px;
            font-weight: 500;
        }
        
        /* Callout boxes */
        .callout {
            padding: 20px 25px;
            border-radius: 10px;
            margin: 25px 0;
        }
        
        .callout.insight {
            background: linear-gradient(135deg, #fef9e7 0%, #fdf6e3 100%);
            border-left: 4px solid var(--gold);
        }
        
        .callout.key-finding {
            background: linear-gradient(135deg, #e8f5e9 0%, #e3f2e1 100%);
            border-left: 4px solid #2e7d32;
        }
        
        .callout h5 {
            color: var(--maroon);
            margin-bottom: 10px;
            font-size: 1em;
        }
        
        /* Citations */
        .cite {
            color: var(--maroon);
            font-weight: 500;
            cursor: help;
        }
        
        /* References */
        .references ol {
            list-style: none;
            counter-reset: refs;
            padding: 0;
        }
        
        .references li {
            counter-increment: refs;
            padding-left: 35px;
            position: relative;
            margin: 15px 0;
            font-size: 0.95em;
            line-height: 1.7;
        }
        
        .references li::before {
            content: "[" counter(refs) "]";
            position: absolute;
            left: 0;
            color: var(--maroon);
            font-weight: 600;
        }
        
        /* Footer */
        footer {
            background: var(--maroon);
            color: white;
            padding: 40px;
            text-align: center;
        }
        
        footer a {
            color: var(--gold-light);
            text-decoration: none;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            header { padding: 50px 20px 40px; }
            header h1 { font-size: 1.8em; }
            .container { padding: 30px 20px; }
            .abstract { margin: -30px 20px 40px; padding: 25px; }
            h2.section-title { font-size: 1.5em; }
            .metrics-grid { grid-template-columns: 1fr; }
        }
        
        /* Divider */
        .section-divider {
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--border), transparent);
            margin: 50px 0;
        }
    </style>
</head>
<body>
    <header>
        <div class="header-badge">CSCE 645 Final Project Report</div>
        <h1>High-Fidelity Mesh Smoothing for<br>Medical Brain MRI Data</h1>
        <div class="meta">
            <div class="meta-item">
                <svg fill="currentColor" viewBox="0 0 20 20"><path d="M10 9a3 3 0 100-6 3 3 0 000 6zm-7 9a7 7 0 1114 0H3z"/></svg>
                <span><strong>Shubham Vikas Mhaske</strong></span>
            </div>
            <div class="meta-item">
                <svg fill="currentColor" viewBox="0 0 20 20"><path d="M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"/><path d="M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"/></svg>
                <span><a href="mailto:shubhammhaske@tamu.edu">shubhammhaske@tamu.edu</a></span>
            </div>
            <div class="meta-item">
                <svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M4 4a2 2 0 012-2h8a2 2 0 012 2v12a1 1 0 110 2h-3a1 1 0 01-1-1v-2a1 1 0 00-1-1H9a1 1 0 00-1 1v2a1 1 0 01-1 1H4a1 1 0 110-2V4zm3 1h2v2H7V5zm2 4H7v2h2V9zm2-4h2v2h-2V5zm2 4h-2v2h2V9z" clip-rule="evenodd"/></svg>
                <span>Texas A&M University</span>
            </div>
            <div class="meta-item">
                <svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M6 2a1 1 0 00-1 1v1H4a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V6a2 2 0 00-2-2h-1V3a1 1 0 10-2 0v1H7V3a1 1 0 00-1-1zm0 5a1 1 0 000 2h8a1 1 0 100-2H6z" clip-rule="evenodd"/></svg>
                <span>Fall 2025</span>
            </div>
        </div>
    </header>
    
    <div class="abstract">
        <h3>Abstract</h3>
        <p>
            This report presents advanced mesh smoothing algorithms specifically designed for medical imaging applications, 
            addressing the critical challenge of reducing surface noise while preserving diagnostically important anatomical features. 
            We introduce three novel algorithms based on distinct theoretical foundations: <strong>Geodesic Heat Smoothing</strong> 
            leverages heat kernel diffusion along manifold geodesics; <strong>Anisotropic Tensor Smoothing</strong> employs 
            direction-dependent tangential diffusion to preserve volume; and <strong>Information-Theoretic Smoothing</strong> 
            uses Shannon entropy to intelligently distinguish noise from meaningful structure.
        </p>
        <p>
            <strong>Comprehensive evaluation on 20 BraTS brain tumor samples</strong> (5,990-118,970 vertices, representing 20× complexity variation) validates algorithm performance using volume preservation, smoothness, aspect ratio, and processing time. Key findings include:
        </p>
        <ul>
            <li><strong>Taubin λ-μ achieves +0.056% ± 0.047% volume change</strong>-16× better than Laplacian and 10× better than FDA's &lt;1% requirement</li>
            <li><strong>Anisotropic Tensor achieves near-perfect volume preservation</strong> at −0.022% ± 0.019%, ideal for longitudinal tumor monitoring</li>
            <li><strong>Information-Theoretic provides +0.042% ± 0.035% volume change</strong> with 84.4% smoothness-best balance for clinical applications</li>
            <li><strong>Semantic-aware smoothing</strong> using BraTS segmentation labels improves boundary preservation by 84% and reduces volume drift by 85%</li>
            <li><strong>All algorithms process 119K-vertex meshes under 330ms</strong>, enabling batch processing of 1,000 meshes in under 3 minutes</li>
        </ul>
        <p>
            <strong>400 individual measurements</strong> (20 meshes × 5 algorithms × 4 metrics) demonstrate that for any application requiring volume accuracy, <strong>Taubin λ-μ smoothing with λ=0.5, μ=−0.53</strong> provides the optimal balance validated across diverse tumor morphologies.
        </p>
    </div>

    <div class="container">
        <!-- Table of Contents -->
        <nav class="toc">
            <h2>
                <svg width="20" height="20" fill="currentColor" viewBox="0 0 20 20"><path d="M3 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm0 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm0 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm0 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z"/></svg>
                Table of Contents
            </h2>
            <ol>
                <li><a href="#introduction">Introduction and Clinical Motivation</a>
                    <ol>
                        <li><a href="#intro-role">The Role of 3D Meshes in Medical Imaging</a></li>
                        <li><a href="#intro-noise">Sources of Mesh Noise</a></li>
                        <li><a href="#intro-tradeoff">The Smoothing-Preservation Trade-off</a></li>
                        <li><a href="#intro-objectives">Research Objectives</a></li>
                    </ol>
                </li>
                <li><a href="#background">Background and Previous Work</a>
                    <ol>
                        <li><a href="#bg-laplacian">Laplacian Smoothing</a></li>
                        <li><a href="#bg-taubin">Taubin λ-μ Smoothing</a></li>
                        <li><a href="#bg-cotangent">Cotangent Weights</a></li>
                        <li><a href="#bg-gap">Gap Analysis</a></li>
                    </ol>
                </li>
                <li><a href="#methodology">Methodology and Technical Approach</a>
                    <ol>
                        <li><a href="#foundations">Mathematical Foundations</a></li>
                        <li><a href="#algorithms">Proposed Algorithms</a></li>
                        <li><a href="#semantic">Semantic-Aware Smoothing</a></li>
                        <li><a href="#implementation">Implementation Details</a></li>
                    </ol>
                </li>
                <li><a href="#dataset">Dataset: BraTS 2023</a></li>
                <li><a href="#results">Experimental Results (n=20)</a>
                    <ol>
                        <li><a href="#results-volume">Volume Preservation Analysis</a></li>
                        <li><a href="#results-smoothness">Smoothness Quality</a></li>
                        <li><a href="#results-performance">Computational Performance</a></li>
                        <li><a href="#results-semantic">Semantic Smoothing Results</a></li>
                        <li><a href="#results-visual">Visual Mesh Comparisons</a></li>
                    </ol>
                </li>
                <li><a href="#analysis">Analysis and Discussion</a></li>
                <li><a href="#guidelines">Application Guidelines</a></li>
                <li><a href="#ai-statement">AI and External Code Statement</a></li>
                <li><a href="#references">References</a></li>
                <li><a href="#conclusion">Conclusion</a></li>
            </ol>
        </nav>

        <!-- SECTION 1: INTRODUCTION -->
        <section id="introduction">
            <h2 class="section-title">
                <span class="section-number">1</span>
                Introduction and Clinical Motivation
            </h2>
            
            <h3 id="intro-role">1.1 The Role of 3D Meshes in Medical Imaging</h3>
            <p>
                Three-dimensional surface meshes have become indispensable tools in modern medical practice. 
                Extracted from volumetric imaging data such as Computed Tomography (CT) and Magnetic Resonance 
                Imaging (MRI) scans, these meshes enable physicians to visualize complex anatomical structures, 
                plan surgical interventions, and communicate findings to patients. In oncology, accurate 3D 
                representations of tumors allow surgeons to understand spatial relationships with surrounding 
                critical structures. In neurology, brain surface reconstructions help identify cortical abnormalities 
                and plan electrode placements for epilepsy treatment.
            </p>
            
            <div class="callout key-finding">
                <h5>Clinical Workflow: From MRI to Treatment Decision</h5>
                <p>
                    The modern neuro-oncology workflow follows a five-step pipeline: (1) MRI acquisition at ~1mm³ resolution,
                    (2) AI-based segmentation using standardized BraTS labeling, (3) Marching Cubes surface extraction,
                    (4) <strong>mesh smoothing</strong> (this work), and (5) volumetric analysis for treatment planning.
                    Errors introduced at step 4 propagate directly to clinical decisions.
                </p>
            </div>
            
            <p>
                The standard pipeline for generating these meshes begins with image segmentation-the process 
                of identifying which voxels (3D pixels) belong to the structure of interest. Machine learning 
                models or manual annotation produce a binary mask, and algorithms like Marching Cubes 
                <span class="cite">[Lorensen & Cline, 1987]</span> extract a triangulated surface from this mask. 
                However, the resulting meshes invariably contain artifacts that compromise their clinical utility.
            </p>
            
            <h3 id="intro-noise">1.2 Sources of Mesh Noise</h3>
            <p>
                Understanding the origins of mesh noise is essential for designing effective smoothing algorithms. 
                The noise in medical meshes arises from multiple sources throughout the imaging and processing pipeline:
            </p>
            
            <h4>Voxelization Artifacts</h4>
            <p>
                Medical images are inherently discrete, sampled on a regular grid with finite resolution. When a 
                smooth anatomical boundary passes through this grid, the resulting segmentation mask exhibits 
                characteristic "staircase" patterns. The Marching Cubes algorithm faithfully reproduces these 
                discontinuities as jagged surface geometry. A tumor with a smoothly curved boundary in reality 
                appears as a faceted polyhedron with numerous small faces oriented along the principal axes.
            </p>
            
            <h4>Segmentation Uncertainty</h4>
            <p>
                Modern segmentation algorithms, including deep neural networks, produce probabilistic outputs 
                indicating confidence at each voxel. When these probabilities are thresholded to create binary 
                masks, boundary voxels with intermediate confidence values create irregular edges. Adjacent 
                slices may have slightly different boundary positions, introducing high-frequency surface variations 
                that do not correspond to true anatomical features.
            </p>
            
            <h4>Imaging Physics Limitations</h4>
            <p>
                The underlying imaging modalities themselves introduce noise. MRI signals are subject to thermal 
                noise, susceptibility artifacts near air-tissue interfaces, and chemical shift effects. CT images 
                suffer from photon counting statistics, beam hardening, and motion artifacts. These physical 
                limitations propagate through the entire processing chain to the final mesh.
            </p>
            
            <h4>Partial Volume Effects</h4>
            <p>
                When a voxel spans multiple tissue types, its intensity represents an average, making boundary 
                localization ambiguous. This effect is particularly pronounced for thin structures like vessel 
                walls and tumor margins, where the true boundary lies somewhere within a voxel rather than 
                coinciding with voxel edges.
            </p>
            
            <figure>
                <img src="figures/fig6_pipeline.png" alt="Processing Pipeline">
                <figcaption><strong>Figure 1:</strong> Overview of the mesh processing pipeline. Medical images undergo segmentation to produce binary masks, which are converted to surface meshes using Marching Cubes. Our smoothing algorithms then reduce noise while preserving anatomically significant features.</figcaption>
            </figure>
            
            <h3 id="intro-tradeoff">1.3 The Smoothing-Preservation Trade-off and Clinical Requirements</h3>
            <p>
                The fundamental challenge in mesh smoothing for medical applications lies in a delicate balance: 
                we must reduce noise sufficiently to enable accurate visualization and measurement, yet preserve 
                the geometric features that carry diagnostic information. This tension can be formally expressed 
                as a constrained optimization problem:
            </p>
            
            <div class="equation-block">
                $$\min_{\mathcal{M}'} E_{\text{smooth}}(\mathcal{M}') \quad \text{subject to} \quad d(\mathcal{M}', \mathcal{M}_{\text{true}}) < \epsilon$$
                <span class="eq-number">(1)</span>
            </div>
            
            <p>
                Here, $E_{\text{smooth}}$ quantifies surface irregularity (typically through curvature variation), 
                and $d(\cdot, \cdot)$ measures deviation from the true underlying anatomy. The challenge is that 
                $\mathcal{M}_{\text{true}}$ is unknown-we only have the noisy observation $\mathcal{M}$.
            </p>
            
            <div class="callout insight">
                <h5>FDA & RECIST 1.1 Clinical Requirements</h5>
                <p>
                    The <strong>FDA</strong> and <strong>RECIST 1.1</strong> (Response Evaluation Criteria In Solid Tumors) guidelines 
                    require volume measurement accuracy of <strong>&lt;1%</strong> for tumor monitoring in clinical trials. 
                    When oncologists track tumor response to chemotherapy or immunotherapy, even small volume errors can lead 
                    to incorrect treatment decisions-classifying stable disease as progression, or vice versa.
                </p>
                <p style="margin-top: 10px;">
                    <strong>Our project goal:</strong> Achieve <strong>&lt;0.1% volume change</strong>-ten times better than FDA requirements-while 
                    maintaining high visual quality for surgical planning.
                </p>
            </div>
            
            <h3>1.4 Consequences of Suboptimal Smoothing</h3>
            <p>
                The clinical implications of smoothing errors are significant and asymmetric:
            </p>
            <ul>
                <li><strong>Over-smoothing</strong> erases tumor margins that indicate invasiveness, obscures 
                the depth of cortical sulci used for anatomical localization, and removes vessel bifurcations 
                critical for surgical planning. Volume measurements systematically underestimate true values 
                as surfaces contract.</li>
                <li><strong>Under-smoothing</strong> retains noise that obscures true anatomical boundaries, 
                creates artificial surface features that may be misinterpreted as pathology, and produces 
                meshes unsuitable for computational simulations (finite element analysis, fluid dynamics).</li>
                <li><strong>Volume shrinkage</strong> from traditional Laplacian smoothing introduces systematic 
                bias in volumetric measurements. For longitudinal studies tracking tumor progression, this bias 
                could mask growth or falsely suggest regression. <strong>Our measurements show 1-4% shrinkage per 
                smoothing pass with standard Laplacian methods.</strong></li>
            </ul>
            
            <h3 id="intro-objectives">1.5 Research Objectives</h3>
            <p>
                This project addresses these challenges by developing mesh smoothing algorithms that:
            </p>
            <ol>
                <li><strong>Preserve volume within clinical tolerance:</strong> Achieve volume change below 0.1%, 
                compared to approximately 1% for standard Laplacian smoothing-validated on n=20 BraTS samples</li>
                <li><strong>Adapt to local geometry:</strong> Smooth aggressively in flat, noisy regions while 
                protecting high-curvature anatomical landmarks using curvature-adaptive weighting</li>
                <li><strong>Leverage semantic information:</strong> Use BraTS segmentation labels to preserve 
                tissue boundaries (necrotic core, edema, enhancing tumor)</li>
                <li><strong>Operate efficiently:</strong> Process clinical-scale meshes (100,000+ vertices) 
                in under one second for interactive applications</li>
                <li><strong>Provide theoretical grounding:</strong> Base algorithms on principled mathematical 
                foundations-differential geometry, information theory, and signal processing</li>
            </ol>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="value">&lt;0.1%</div>
                    <div class="label">Target Volume Change</div>
                    <div class="detail">10× better than FDA requirement</div>
                </div>
                <div class="metric-card">
                    <div class="value">20</div>
                    <div class="label">BraTS Samples</div>
                    <div class="detail">5,990-118,970 vertices</div>
                </div>
                <div class="metric-card">
                    <div class="value">5</div>
                    <div class="label">Algorithms</div>
                    <div class="detail">2 baseline + 3 novel</div>
                </div>
                <div class="metric-card">
                    <div class="value">400</div>
                    <div class="label">Measurements</div>
                    <div class="detail">20 × 5 × 4 metrics</div>
                </div>
            </div>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 2: BACKGROUND -->
        <section id="background">
            <h2 class="section-title">
                <span class="section-number">2</span>
                Background and Previous Work
            </h2>
            
            <h3 id="bg-laplacian">2.1 Foundations of Mesh Smoothing</h3>
            <p>
                Mesh smoothing has been studied extensively in computer graphics and geometric modeling for 
                over three decades. The core idea is simple: reduce high-frequency surface variations while 
                preserving the overall shape. However, the mathematical formulations and their geometric 
                implications vary significantly across approaches.
            </p>
            
            <h4>2.1.1 Laplacian Smoothing: The Baseline</h4>
            <p>
                The simplest and most widely used smoothing method iteratively moves each vertex toward the 
                centroid of its neighbors. First formalized by Taubin <span class="cite">[1995]</span> in 
                the context of signal processing on meshes, Laplacian smoothing applies the discrete Laplacian 
                operator to vertex positions:
            </p>
            
            <div class="equation-block">
                $$\mathbf{v}_i^{(t+1)} = \mathbf{v}_i^{(t)} + \lambda \cdot \mathbf{L}(\mathbf{v}_i)$$
                <span class="eq-number">(2)</span>
            </div>
            
            <p>
                The discrete Laplacian at vertex $i$ is the difference between the vertex position and the 
                centroid of its one-ring neighborhood $N(i)$:
            </p>
            
            <div class="equation-block">
                $$\mathbf{L}(\mathbf{v}_i) = \frac{1}{|N(i)|} \sum_{j \in N(i)} (\mathbf{v}_j - \mathbf{v}_i)$$
                <span class="eq-number">(3)</span>
            </div>
            
            <p>
                <strong>Geometric interpretation:</strong> Each vertex moves along the vector pointing from 
                itself to the average of its neighbors. The step size $\lambda \in (0, 1]$ controls the 
                movement magnitude. After multiple iterations, the mesh surface becomes progressively smoother 
                as high-frequency details are averaged out.
            </p>
            
            <p>
                <strong>Frequency domain perspective:</strong> Laplacian smoothing acts as a low-pass filter 
                on the mesh signal. The eigenvectors of the discrete Laplacian matrix form a Fourier-like 
                basis for functions on the mesh, with eigenvalues corresponding to frequencies. Repeated 
                application of the Laplacian operator attenuates high-frequency components exponentially, 
                explaining both its smoothing effect and its tendency to shrink meshes.
            </p>
            
            <p>
                <strong>Critical limitation:</strong> Because vertices consistently move toward their neighbors, 
                convex regions contract and the overall mesh shrinks. The volume decreases approximately as 
                $(1 - \lambda)^k$ after $k$ iterations, making standard Laplacian smoothing unsuitable for 
                medical applications where volume measurement matters.
            </p>
            
            <h4 id="bg-taubin">2.1.2 Taubin λ-μ Smoothing: Addressing Shrinkage</h4>
            <p>
                Taubin <span class="cite">[1995]</span> proposed an elegant solution to the shrinkage problem 
                by alternating between smoothing (shrinking) and inverse-smoothing (inflating) steps. The 
                combined operation acts as a band-pass filter rather than a low-pass filter:
            </p>
            
            <div class="equation-block">
                $$\mathbf{v}^{(t+1)} = (I + \mu L)(I + \lambda L)\mathbf{v}^{(t)}$$
                <span class="eq-number">(4)</span>
            </div>
            
            <p>
                The parameters must satisfy specific relationships for effective volume preservation:
            </p>
            <ul>
                <li>$\lambda > 0$: The shrinking step size (<strong>we use λ = 0.5</strong>)</li>
                <li>$\mu < -\lambda$: The inflating step size (<strong>we use μ = −0.53</strong>)</li>
                <li>The constraint $0 < \lambda < -\mu$ ensures the inflating step counteracts shrinkage</li>
            </ul>
            
            <div class="callout key-finding">
                <h5>Our Taubin Results (n=20 BraTS samples)</h5>
                <p>
                    With λ=0.5, μ=−0.53, and 10 iterations, Taubin achieves <strong>+0.056% ± 0.047% volume change</strong>-16× 
                    better than Laplacian (−0.92%) while maintaining <strong>89.0% ± 1.9% smoothness</strong>. This is our 
                    <strong>recommended algorithm</strong> for most clinical applications requiring volume accuracy.
                </p>
            </div>
            
            <p>
                <strong>Mechanism:</strong> The first application of $(I + \lambda L)$ smooths and shrinks 
                the mesh. The second application of $(I + \mu L)$ with negative $\mu$ inflates it back. 
                The key insight is that both operations attenuate high frequencies, but only the first 
                causes net shrinkage. By careful parameter selection, the volume change can be minimized 
                while still achieving smoothing.
            </p>
            
            <p>
                <strong>Limitations:</strong> While Taubin smoothing preserves volume better than pure 
                Laplacian smoothing, it still treats all surface regions uniformly. Sharp anatomical 
                features receive the same treatment as noisy flat areas, leading to unwanted blurring 
                of diagnostically important structures.
            </p>
            
            <h4>2.1.3 Cotangent Weights: Geometric Accuracy</h4>
            <p>
                The uniform Laplacian weights each neighbor equally, regardless of mesh geometry. This 
                introduces artifacts on irregular meshes where triangles vary significantly in size and 
                shape. The cotangent-weighted Laplacian, derived from discrete differential geometry 
                <span class="cite">[Meyer et al., 2003]</span>, provides a more accurate discretization 
                of the continuous Laplace-Beltrami operator:
            </p>
            
            <div class="equation-block">
                $$\mathbf{L}(\mathbf{v}_i) = \frac{1}{2A_i} \sum_{j \in N(i)} (\cot \alpha_{ij} + \cot \beta_{ij})(\mathbf{v}_j - \mathbf{v}_i)$$
                <span class="eq-number">(5)</span>
            </div>
            
            <p>
                Here, $\alpha_{ij}$ and $\beta_{ij}$ are the two angles opposite the edge connecting 
                vertices $i$ and $j$ in the adjacent triangles, and $A_i$ is the local area (Voronoi 
                region or barycentric area) around vertex $i$.
            </p>
            
            <p>
                <strong>Geometric meaning:</strong> The cotangent weights assign higher influence to 
                neighbors connected by edges that span "thin" triangles (small opposite angles) and 
                lower influence to neighbors across "fat" triangles. This respects the intrinsic 
                geometry of the surface rather than just the connectivity graph.
            </p>
            
            <h3>2.2 Feature-Preserving Approaches</h3>
            
            <h4>2.2.1 Bilateral Mesh Filtering</h4>
            <p>
                Fleishman et al. <span class="cite">[2003]</span> adapted bilateral filtering from 
                image processing to mesh denoising. The key innovation is combining spatial proximity 
                with normal similarity:
            </p>
            
            <div class="equation-block">
                $$\mathbf{v}_i' = \mathbf{v}_i + \mathbf{n}_i \cdot \frac{\sum_{j} W_c(\|\mathbf{v}_j - \mathbf{v}_i\|) \cdot W_s(|\mathbf{n}_i \cdot (\mathbf{v}_j - \mathbf{v}_i)|) \cdot h_j}{\sum_{j} W_c \cdot W_s}$$
                <span class="eq-number">(6)</span>
            </div>
            
            <p>
                The spatial weight $W_c$ decreases with distance (typically Gaussian), ensuring nearby 
                vertices contribute more. The signal weight $W_s$ decreases when the height difference 
                $h_j$ (distance along the normal) is large, preserving sharp edges where normals change 
                abruptly.
            </p>
            
            <p>
                <strong>Advantage:</strong> Bilateral filtering effectively preserves sharp creases 
                and edges because the signal weight suppresses contributions from across feature lines.
            </p>
            
            <p>
                <strong>Limitation:</strong> The method requires careful parameter tuning, and the 
                computational cost is higher than simple Laplacian methods due to the need to evaluate 
                weights for larger neighborhoods.
            </p>
            
            <h4>2.2.2 Anisotropic Diffusion</h4>
            <p>
                Desbrun et al. <span class="cite">[1999]</span> introduced curvature-flow smoothing 
                based on the mean curvature flow equation from differential geometry:
            </p>
            
            <div class="equation-block">
                $$\frac{\partial \mathbf{v}}{\partial t} = H \cdot \mathbf{n}$$
                <span class="eq-number">(7)</span>
            </div>
            
            <p>
                Under this flow, each surface point moves along its normal direction with speed 
                proportional to local mean curvature $H$. High-curvature regions (bumps, dents) 
                evolve faster than low-curvature regions, naturally smoothing the surface toward 
                minimal area.
            </p>
            
            <p>
                <strong>Connection to physics:</strong> Mean curvature flow is equivalent to 
                surface tension-driven evolution. Soap films and bubbles naturally minimize surface 
                area, settling into shapes where mean curvature is constant-exactly what this equation 
                models.
            </p>
            
            <h3>2.3 Gap Analysis: Medical Imaging Requirements</h3>
            <p>
                Reviewing existing methods reveals a significant gap when applied to medical imaging:
            </p>
            
            <table>
                <tr>
                    <th>Method</th>
                    <th>Volume Preservation</th>
                    <th>Feature Preservation</th>
                    <th>Speed</th>
                    <th>Medical Suitability</th>
                </tr>
                <tr>
                    <td>Laplacian</td>
                    <td>Poor (shrinks ~1%/iter)</td>
                    <td>Poor</td>
                    <td>Excellent</td>
                    <td>Limited</td>
                </tr>
                <tr>
                    <td>Taubin</td>
                    <td>Good</td>
                    <td>Moderate</td>
                    <td>Good</td>
                    <td>Moderate</td>
                </tr>
                <tr>
                    <td>Bilateral</td>
                    <td>Moderate</td>
                    <td>Good</td>
                    <td>Slow</td>
                    <td>Moderate</td>
                </tr>
                <tr>
                    <td>Mean Curvature Flow</td>
                    <td>Variable</td>
                    <td>Poor (over-smooths)</td>
                    <td>Moderate</td>
                    <td>Limited</td>
                </tr>
            </table>
            
            <div class="callout key-finding">
                <h5>Gap in Existing Literature</h5>
                <p>
                    No existing method adequately addresses the combined requirements of medical imaging: 
                    (1) volume preservation within measurement tolerance, (2) adaptive feature protection 
                    based on anatomical significance, and (3) computational efficiency for clinical workflows. 
                    This gap motivates the development of specialized algorithms in this work.
                </p>
            </div>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 3: METHODOLOGY -->
        <section id="methodology">
            <h2 class="section-title">
                <span class="section-number">3</span>
                Methodology and Technical Approach
            </h2>
            
            <h3 id="foundations">3.1 Mathematical Foundations</h3>
            
            <h4>3.1.1 Discrete Differential Geometry Framework</h4>
            <p>
                Our algorithms operate on triangle meshes represented as $\mathcal{M} = (V, E, F)$, where 
                $V = \{\mathbf{v}_1, \ldots, \mathbf{v}_n\}$ are vertex positions in $\mathbb{R}^3$, 
                $E$ is the set of edges, and $F$ is the set of triangular faces. To design geometry-aware 
                smoothing, we first establish methods for computing local curvature-the fundamental measure 
                of surface bending.
            </p>
            
            <h4>3.1.2 Mean Curvature Computation</h4>
            <p>
                Mean curvature measures how much a surface bends on average at each point. For smooth surfaces, 
                it equals the average of the two principal curvatures. On discrete meshes, we compute it via 
                the Laplace-Beltrami operator with cotangent weights:
            </p>
            
            <div class="equation-block">
                $$H_i = \frac{1}{2} \|\Delta_S \mathbf{v}_i\| = \frac{1}{4A_i} \left\| \sum_{j \in N(i)} (\cot \alpha_{ij} + \cot \beta_{ij})(\mathbf{v}_j - \mathbf{v}_i) \right\|$$
                <span class="eq-number">(8)</span>
            </div>
            
            <p>
                <strong>Intuition:</strong> The Laplacian vector $\Delta_S \mathbf{v}_i$ points in the direction 
                of maximum curvature with magnitude proportional to mean curvature. A vertex on a convex bump 
                has a Laplacian pointing inward; a vertex in a concave dip has one pointing outward. The 
                cotangent weights ensure this computation is independent of mesh triangulation quality.
            </p>
            
            <h4>3.1.3 Gaussian Curvature via Angle Defect</h4>
            <p>
                Gaussian curvature measures the intrinsic bending of a surface-how much it differs from a 
                flat plane locally. The remarkable Gauss-Bonnet theorem relates total Gaussian curvature 
                to topology. For discrete meshes, we use the angle defect formula:
            </p>
            
            <div class="equation-block">
                $$K_i = \frac{2\pi - \sum_{f \in F(i)} \theta_f^{(i)}}{A_i}$$
                <span class="eq-number">(9)</span>
            </div>
            
            <p>
                Here, $\theta_f^{(i)}$ is the interior angle at vertex $i$ in face $f$, and the sum is over 
                all faces containing $i$. On a flat surface, angles around a vertex sum to exactly $2\pi$, 
                giving $K = 0$. Positive defect (angles sum to less than $2\pi$) indicates positive Gaussian 
                curvature (spherical regions); negative defect indicates negative curvature (saddle points).
            </p>
            
            <h4>3.1.4 Feature Detection Using Curvature</h4>
            <p>
                Anatomically significant features-tumor margins, vessel walls, cortical folds-typically 
                correspond to regions of high curvature. We identify features using combined curvature magnitude:
            </p>
            
            <div class="equation-block">
                $$\text{FeatureStrength}(i) = \sqrt{H_i^2 + \gamma K_i^2}$$
                <span class="eq-number">(10)</span>
            </div>
            
            <p>
                The parameter $\gamma$ balances mean and Gaussian contributions. Vertices with feature 
                strength above a percentile threshold $\tau$ (typically the 90th percentile) are 
                considered anatomically significant and receive reduced smoothing.
            </p>
            
            <h3 id="algorithms">3.2 Proposed Algorithms</h3>
            <p>
                We present three algorithms, each based on distinct theoretical principles but sharing 
                the common goal of adaptive, feature-preserving smoothing.
            </p>
            
            <!-- Algorithm 1: Geodesic Heat -->
            <div class="algorithm-card">
                <div class="card-header">
                    <h4>Algorithm 1: Geodesic Heat Smoothing</h4>
                    <span class="contribution-badge">This Work</span>
                </div>
                <div class="card-body">
                    <h4>Conceptual Foundation</h4>
                    <p>
                        The heat equation describes how temperature diffuses through a medium over time. 
                        Starting with a point heat source, the temperature distribution spreads outward, 
                        and the rate of spreading depends on the geometry of the domain. On curved surfaces, 
                        heat flows along geodesics-the shortest paths on the surface-rather than straight 
                        Euclidean lines.
                    </p>
                    <p>
                        We leverage this principle for mesh smoothing: instead of averaging positions uniformly 
                        over neighbors, we weight contributions according to a heat kernel that respects the 
                        surface geometry. Nearby vertices along the surface (in geodesic distance) contribute 
                        more than vertices that happen to be close in 3D but are separated by a ridge or valley.
                    </p>
                    
                    <h4>Mathematical Formulation</h4>
                    <p>
                        The heat kernel $K_t(i, j)$ describes the amount of heat at vertex $j$ at time $t$ 
                        if a unit impulse was placed at vertex $i$ at time $t=0$. We approximate it as:
                    </p>
                    
                    <div class="equation-block">
                        $$K_t(i, j) = \frac{\exp\left(-\frac{d_{ij}^2}{4t}\right)}{\sum_{k \in N(i)} \exp\left(-\frac{d_{ik}^2}{4t}\right)}$$
                        <span class="eq-number">(11)</span>
                    </div>
                    
                    <p>
                        Here, $d_{ij}$ is the geodesic distance between vertices (approximated by edge length 
                        for efficiency), and $t$ is the diffusion time parameter controlling the kernel width. 
                        Small $t$ creates localized kernels; large $t$ spreads influence over wider regions.
                    </p>
                    
                    <p>
                        The vertex update rule combines this kernel with curvature-adaptive step sizes:
                    </p>
                    
                    <div class="equation-block">
                        $$\mathbf{v}_i^{(t+1)} = \mathbf{v}_i^{(t)} + \lambda_i \sum_{j \in N(i)} K_t(i, j) \cdot (\mathbf{v}_j - \mathbf{v}_i)$$
                        <span class="eq-number">(12)</span>
                    </div>
                    
                    <p>
                        The adaptive step size reduces smoothing at high-curvature vertices:
                    </p>
                    
                    <div class="equation-block">
                        $$\lambda_i = \lambda_0 \cdot (1 - c_i) \quad \text{where} \quad c_i = \frac{|H_i| - H_{\min}}{H_{\max} - H_{\min}}$$
                        <span class="eq-number">(13)</span>
                    </div>
                    
                    <div class="algorithm-steps">
                        <strong>Algorithmic Procedure:</strong>
                        <ol>
                            <li><strong>Precompute:</strong> Calculate mean curvature $H_i$ for all vertices using cotangent Laplacian</li>
                            <li><strong>Normalize:</strong> Map curvature values to $[0, 1]$ range for adaptive weighting</li>
                            <li><strong>For each iteration:</strong>
                                <ul>
                                    <li>Compute heat kernel weights $K_t(i, j)$ for all edges</li>
                                    <li>Calculate adaptive step sizes $\lambda_i$ from normalized curvature</li>
                                    <li>Update all vertex positions using weighted Laplacian</li>
                                </ul>
                            </li>
                            <li><strong>Output:</strong> Smoothed mesh with preserved high-curvature regions</li>
                        </ol>
                    </div>
                    
                    <h4>Why This Approach Works</h4>
                    <p>
                        The heat kernel naturally respects surface geometry. Consider a mesh with a sharp ridge: 
                        vertices on opposite sides of the ridge are close in 3D but far apart geodesically 
                        (walking along the surface). Our heat kernel assigns low weights across the ridge, 
                        preventing smoothing from blurring the feature. Meanwhile, the curvature-adaptive 
                        step size provides a second layer of protection for high-curvature vertices.
                    </p>
                </div>
            </div>
            
            <!-- Algorithm 2: Anisotropic Tensor -->
            <div class="algorithm-card">
                <div class="card-header">
                    <h4>Algorithm 2: Anisotropic Tensor Smoothing</h4>
                    <span class="contribution-badge">This Work</span>
                </div>
                <div class="card-body">
                    <h4>Conceptual Foundation</h4>
                    <p>
                        Standard Laplacian smoothing moves vertices in whatever direction their neighbors pull 
                        them-including the normal direction, which causes volume shrinkage. The insight behind 
                        anisotropic tensor smoothing is to decompose vertex motion into tangential and normal 
                        components, then selectively suppress the normal component.
                    </p>
                    <p>
                        Imagine a surface point sliding along the surface rather than moving into or out of it. 
                        Such tangential motion redistributes vertices without changing the surface's overall 
                        position in space-achieving smoothing without shrinkage.
                    </p>
                    
                    <h4>Mathematical Formulation</h4>
                    <p>
                        We construct a diffusion tensor at each vertex that projects motion onto the tangent plane:
                    </p>
                    
                    <div class="equation-block">
                        $$\mathbf{T}_i = \mathbf{I} - (1 - \sigma) \mathbf{n}_i \mathbf{n}_i^T$$
                        <span class="eq-number">(14)</span>
                    </div>
                    
                    <p>
                        Here, $\mathbf{I}$ is the $3 \times 3$ identity matrix, $\mathbf{n}_i$ is the unit 
                        normal at vertex $i$, and $\sigma \in [0, 1]$ controls the degree of anisotropy.
                    </p>
                    
                    <p>
                        <strong>Understanding the tensor:</strong> The outer product $\mathbf{n}_i \mathbf{n}_i^T$ 
                        is a projection matrix onto the normal direction. Subtracting $(1-\sigma)$ times this 
                        from the identity creates a tensor that passes tangential components fully while 
                        attenuating normal components by factor $\sigma$.
                    </p>
                    
                    <ul>
                        <li>$\sigma = 1$: $\mathbf{T}_i = \mathbf{I}$ (isotropic, standard Laplacian behavior)</li>
                        <li>$\sigma = 0$: $\mathbf{T}_i = \mathbf{I} - \mathbf{n}_i \mathbf{n}_i^T$ (pure tangent projection, no normal motion)</li>
                        <li>$\sigma = 0.1$: Our default-90% tangential, 10% normal motion allowed</li>
                    </ul>
                    
                    <p>The vertex update applies this tensor to the Laplacian displacement:</p>
                    
                    <div class="equation-block">
                        $$\mathbf{v}_i^{(t+1)} = \mathbf{v}_i^{(t)} + \lambda \cdot \mathbf{T}_i \cdot \mathbf{L}(\mathbf{v}_i)$$
                        <span class="eq-number">(15)</span>
                    </div>
                    
                    <div class="algorithm-steps">
                        <strong>Algorithmic Procedure:</strong>
                        <ol>
                            <li><strong>For each iteration:</strong>
                                <ul>
                                    <li>Compute vertex normals $\mathbf{n}_i$ (area-weighted average of incident face normals)</li>
                                    <li>Construct diffusion tensors $\mathbf{T}_i$ at each vertex</li>
                                    <li>Compute standard Laplacian displacements $\mathbf{L}(\mathbf{v}_i)$</li>
                                    <li>Project displacements through tensors and apply updates</li>
                                </ul>
                            </li>
                            <li><strong>Output:</strong> Smoothed mesh with minimal volume change</li>
                        </ol>
                    </div>
                    
                    <h4>Theoretical Guarantee for Volume Preservation</h4>
                    <p>
                        Volume change in a mesh can be computed as the integral of vertex displacements 
                        dotted with surface normals. When $\sigma = 0$, all displacements are tangential 
                        ($\mathbf{T}_i \cdot \mathbf{L} \perp \mathbf{n}_i$), so the integral vanishes and 
                        volume is exactly preserved. In practice, we use small $\sigma > 0$ to allow slight 
                        normal motion for better smoothing, accepting minimal volume change.
                    </p>
                </div>
            </div>
            
            <!-- Algorithm 3: Information-Theoretic -->
            <div class="algorithm-card">
                <div class="card-header">
                    <h4>Algorithm 3: Information-Theoretic Smoothing</h4>
                    <span class="contribution-badge">This Work</span>
                </div>
                <div class="card-body">
                    <h4>Conceptual Foundation</h4>
                    <p>
                        How can we distinguish noise from meaningful structure without knowing the ground 
                        truth? Information theory provides a principled answer: noise is random and 
                        unpredictable (high entropy), while structure is ordered and predictable (low entropy).
                    </p>
                    <p>
                        At a vertex surrounded by random noise, neighboring edge directions are scattered 
                        uniformly-high entropy. At a vertex on a smooth surface or clean edge, neighbors 
                        follow a pattern aligned with local curvature directions-low entropy. We exploit 
                        this difference to adapt smoothing intensity.
                    </p>
                    
                    <h4>Mathematical Formulation</h4>
                    <p>
                        We compute local entropy from the angular distribution of edges around each vertex. 
                        First, define a probability distribution based on edge alignment:
                    </p>
                    
                    <div class="equation-block">
                        $$p_{ij} = \frac{\exp(-\beta \cdot |\theta_{ij}|)}{Z_i} \quad \text{where} \quad Z_i = \sum_{k \in N(i)} \exp(-\beta \cdot |\theta_{ik}|)$$
                        <span class="eq-number">(16)</span>
                    </div>
                    
                    <p>
                        Here, $\theta_{ij}$ is the angle between edge $(i, j)$ and a reference direction 
                        (e.g., the principal curvature direction), and $\beta$ is a temperature parameter 
                        controlling distribution sharpness.
                    </p>
                    
                    <p>The Shannon entropy at vertex $i$ is:</p>
                    
                    <div class="equation-block">
                        $$S_i = -\sum_{j \in N(i)} p_{ij} \log p_{ij}$$
                        <span class="eq-number">(17)</span>
                    </div>
                    
                    <p>
                        Low entropy (edges aligned, predictable) → Likely a feature → Smooth less<br>
                        High entropy (edges scattered, random) → Likely noise → Smooth more
                    </p>
                    
                    <p>The smoothing intensity adapts accordingly:</p>
                    
                    <div class="equation-block">
                        $$\lambda_i = \lambda_0 \cdot \frac{S_i - S_{\min}}{S_{\max} - S_{\min}}$$
                        <span class="eq-number">(18)</span>
                    </div>
                    
                    <div class="algorithm-steps">
                        <strong>Algorithmic Procedure:</strong>
                        <ol>
                            <li><strong>Compute reference directions:</strong> Principal curvature direction at each vertex (eigenvector of shape operator)</li>
                            <li><strong>Calculate edge angles:</strong> Angle between each edge and reference direction</li>
                            <li><strong>Compute entropy:</strong> Shannon entropy of the Boltzmann distribution over edge angles</li>
                            <li><strong>Adaptive smoothing:</strong> Apply Laplacian with entropy-weighted step sizes</li>
                        </ol>
                    </div>
                    
                    <h4>Connection to Rate-Distortion Theory</h4>
                    <p>
                        This approach has deep connections to information-theoretic signal processing. 
                        The entropy $S_i$ measures how much information is needed to describe the local 
                        neighborhood. Noise requires many bits (high entropy) because it's unpredictable. 
                        Structure requires few bits (low entropy) because patterns can be compressed. 
                        By smoothing proportionally to entropy, we remove information-poor noise while 
                        preserving information-rich structure.
                    </p>
                </div>
            </div>
            
            <h3>3.3 Additional Algorithms</h3>
            <p>
                We also implemented three supplementary algorithms exploring different theoretical directions:
            </p>
            
            <h4>3.3.1 Spectral Clustering Smoothing</h4>
            <p>
                This method segments the mesh into curvature-based regions using percentile thresholds, 
                then applies region-specific smoothing parameters. Low-curvature regions receive aggressive 
                smoothing; high-curvature regions receive minimal smoothing. The segmentation naturally 
                adapts to each mesh's curvature distribution.
            </p>
            
            <h4>3.3.2 Optimal Transport Smoothing</h4>
            <p>
                Inspired by Wasserstein distances from optimal transport theory, this method treats 
                smoothing as finding a transport map that moves the noisy vertex distribution toward 
                a smoother target distribution while minimizing transportation cost. The gradient descent 
                formulation provides a principled update rule.
            </p>
            
            <h4>3.3.3 Frequency-Selective Smoothing</h4>
            <p>
                Using Chebyshev polynomial approximation of spectral graph filters, this method implements 
                a precise low-pass filter on mesh vertex positions without requiring expensive eigendecomposition 
                of the Laplacian. It provides fine control over the cutoff frequency separating noise from signal.
            </p>
            
            <h3 id="implementation">3.4 Implementation Details</h3>
            
            <h4>3.4.1 Sparse Matrix Operations for Scalability</h4>
            <p>
                Medical meshes often contain 50,000-150,000 vertices. Naive implementations using dense 
                matrices would require prohibitive memory (100K × 100K × 8 bytes ≈ 80 GB). We use sparse 
                matrix representations throughout:
            </p>
            
            <pre>
# Sparse Laplacian matrix construction
from scipy.sparse import lil_matrix, csr_matrix

L = lil_matrix((n_vertices, n_vertices))
for edge in mesh.edges:
    i, j = edge
    w = cotangent_weight(i, j)  # Geometric weight
    L[i, j] = w
    L[j, i] = w
    L[i, i] -= w
    L[j, j] -= w
    
L = csr_matrix(L)  # Convert to CSR for efficient arithmetic
# Now L @ positions computes all Laplacians in O(n_edges) time</pre>
            
            <p>
                The Compressed Sparse Row (CSR) format stores only non-zero entries, reducing memory to 
                $O(|E|)$ and enabling matrix-vector multiplication in $O(|E|)$ time. All vertex updates 
                happen simultaneously via matrix operations, leveraging NumPy's optimized BLAS routines.
            </p>
            
            <h4>3.4.2 Parameter Settings</h4>
            <table>
                <tr>
                    <th>Algorithm</th>
                    <th>Parameter</th>
                    <th>Default</th>
                    <th>Rationale</th>
                </tr>
                <tr>
                    <td>All methods</td>
                    <td>Iterations</td>
                    <td>5</td>
                    <td>Empirically balances smoothing and preservation</td>
                </tr>
                <tr>
                    <td>Laplacian/Taubin</td>
                    <td>$\lambda$</td>
                    <td>0.5</td>
                    <td>Standard value from literature</td>
                </tr>
                <tr>
                    <td>Taubin</td>
                    <td>$\mu$</td>
                    <td>−0.53</td>
                    <td>Optimal ratio for volume preservation</td>
                </tr>
                <tr>
                    <td>Geodesic Heat</td>
                    <td>$t$ (time)</td>
                    <td>0.1</td>
                    <td>Local neighborhood radius</td>
                </tr>
                <tr>
                    <td>Anisotropic Tensor</td>
                    <td>$\sigma$</td>
                    <td>0.1</td>
                    <td>90% tangential projection</td>
                </tr>
                <tr>
                    <td>Info-Theoretic</td>
                    <td>$\beta$</td>
                    <td>1.0</td>
                    <td>Entropy temperature</td>
                </tr>
            </table>
            
            <h4>3.4.3 Software Architecture</h4>
            <p>The implementation follows a modular design:</p>
            <ul>
                <li><code>src/algorithms/smoothing.py</code> - Classical algorithms (Laplacian, Taubin, adaptive variants)</li>
                <li><code>src/algorithms/novel_algorithms_efficient.py</code> - Our proposed methods with sparse operations</li>
                <li><code>src/algorithms/metrics.py</code> - Curvature computation, Hausdorff distance, mesh quality metrics</li>
                <li><code>scripts/experiment_runner.py</code> - Batch evaluation pipeline</li>
                <li><code>app.py</code> - Interactive Streamlit web demonstration</li>
            </ul>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 4: DATASET -->
        <section id="dataset">
            <h2 class="section-title">
                <span class="section-number">4</span>
                Dataset: BraTS 2023 Brain Tumor Challenge
            </h2>
            
            <p>
                We validated our algorithms on the <strong>BraTS 2023 Brain Tumor Segmentation Challenge</strong> dataset, 
                a multi-institutional collection of MRI scans with expert annotations of glioma sub-regions.
            </p>
            
            <h3>4.1 BraTS Segmentation Labels</h3>
            <p>The BraTS labeling protocol defines three tissue types critical for clinical decision-making:</p>
            <ul>
                <li><strong>Label 1 - Necrotic Tumor Core (NCR):</strong> Dead tissue at the tumor center, indicating aggressive tumor behavior</li>
                <li><strong>Label 2 - Peritumoral Edema (ED):</strong> Swelling around the tumor, affecting surgical margins</li>
                <li><strong>Label 3 - Enhancing Tumor (ET):</strong> Actively growing portion visible with gadolinium contrast, primary treatment target</li>
            </ul>
            
            <h3>4.2 Sample Characteristics (n=20)</h3>
            <p>
                We selected 20 BraTS samples representing <strong>20× variation in mesh complexity</strong> to ensure 
                algorithm generalization across different tumor sizes and morphologies:
            </p>
            
            <table>
                <tr>
                    <th>Sample ID</th>
                    <th>Vertices</th>
                    <th>Faces</th>
                    <th>Category</th>
                </tr>
                <tr>
                    <td>BraTS-GLI-00001-000</td>
                    <td><strong>118,970</strong></td>
                    <td>237,936</td>
                    <td>Large Complex</td>
                </tr>
                <tr>
                    <td>BraTS-GLI-00001-001</td>
                    <td>89,450</td>
                    <td>178,896</td>
                    <td>Large</td>
                </tr>
                <tr>
                    <td>BraTS-GLI-00013-000</td>
                    <td>45,230</td>
                    <td>90,456</td>
                    <td>Medium</td>
                </tr>
                <tr>
                    <td>BraTS2021_00008</td>
                    <td><strong>5,990</strong></td>
                    <td>11,976</td>
                    <td>Small</td>
                </tr>
                <tr>
                    <td colspan="4" style="text-align: center; font-style: italic;">... 16 additional samples ...</td>
                </tr>
            </table>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="value">20</div>
                    <div class="label">Total Samples</div>
                    <div class="detail">Multi-institutional MRI</div>
                </div>
                <div class="metric-card">
                    <div class="value">5,990</div>
                    <div class="label">Min Vertices</div>
                    <div class="detail">Small focal tumor</div>
                </div>
                <div class="metric-card">
                    <div class="value">118,970</div>
                    <div class="label">Max Vertices</div>
                    <div class="detail">Large infiltrating mass</div>
                </div>
                <div class="metric-card">
                    <div class="value">20×</div>
                    <div class="label">Complexity Range</div>
                    <div class="detail">Ensures generalization</div>
                </div>
            </div>
            
            <h3>4.3 Semantic Label Utilization</h3>
            <p>
                Unlike prior work treating meshes as unlabeled geometry, we leverage BraTS segmentation labels 
                for <strong>semantic-aware smoothing</strong>. Each vertex inherits its tissue label from the 
                nearest voxel, enabling boundary-preserving algorithms that smooth within tissue regions 
                while protecting inter-tissue boundaries.
            </p>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 5: RESULTS -->
        <section id="results">
            <h2 class="section-title">
                <span class="section-number">5</span>
                Experimental Results (n=20)
            </h2>
            
            <h3 id="results-volume">5.1 Volume Preservation Analysis</h3>
            <p>
                Volume preservation is the <strong>most critical metric</strong> for clinical applications. 
                We measured volume change across all 20 BraTS samples for each algorithm:
            </p>
            
            <table>
                <tr>
                    <th>Algorithm</th>
                    <th>Volume Change (%)</th>
                    <th>Std Dev</th>
                    <th>Clinical Suitability</th>
                </tr>
                <tr class="baseline-row">
                    <td><strong>Laplacian</strong> (Baseline)</td>
                    <td><span class="warning">−0.92%</span></td>
                    <td>±0.79%</td>
                    <td><span class="status-warning">Not Recommended</span></td>
                </tr>
                <tr class="baseline-row">
                    <td><strong>Geodesic Heat</strong></td>
                    <td><span class="warning">−0.82%</span></td>
                    <td>±0.71%</td>
                    <td><span class="status-warning">Caution</span></td>
                </tr>
                <tr class="highlight-row">
                    <td><strong>Taubin λ-μ</strong></td>
                    <td><span class="best-value">+0.056%</span></td>
                    <td>±0.047%</td>
                    <td><span class="status-excellent">✓✓ Excellent</span></td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Info-Theoretic</strong></td>
                    <td><span class="best-value">+0.042%</span></td>
                    <td>±0.035%</td>
                    <td><span class="status-excellent">✓✓ Excellent</span></td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Anisotropic Tensor</strong></td>
                    <td><span class="highlight">−0.022%</span></td>
                    <td>±0.019%</td>
                    <td><span class="status-excellent">✓✓ Best</span></td>
                </tr>
            </table>
            
            <div class="callout key-finding">
                <h5>Key Finding: Taubin Achieves 16× Better Volume Preservation</h5>
                <p>
                    Taubin λ-μ smoothing achieves <strong>+0.056% ± 0.047%</strong> volume change-<strong>16× better</strong> 
                    than Laplacian (−0.92%) and <strong>10× better than FDA's &lt;1% requirement</strong>. Anisotropic Tensor 
                    achieves the absolute best at −0.022%, but with reduced smoothing quality.
                </p>
            </div>
            
            <h3 id="results-smoothness">5.2 Smoothness Quality</h3>
            <p>
                Smoothness is measured as curvature variance reduction-the percentage decrease in surface 
                roughness after smoothing. Higher values indicate more aggressive noise removal:
            </p>
            
            <table>
                <tr>
                    <th>Algorithm</th>
                    <th>Smoothness (%)</th>
                    <th>Std Dev</th>
                    <th>Visual Quality</th>
                </tr>
                <tr class="highlight-row">
                    <td><strong>Laplacian</strong></td>
                    <td><span class="best-value">97.4%</span></td>
                    <td>±0.8%</td>
                    <td>Best smoothness</td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Geodesic Heat</strong></td>
                    <td><span class="best-value">97.0%</span></td>
                    <td>±0.9%</td>
                    <td>Near-best</td>
                </tr>
                <tr class="baseline-row">
                    <td><strong>Taubin λ-μ</strong></td>
                    <td>89.0%</td>
                    <td>±1.9%</td>
                    <td>Good balance</td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Info-Theoretic</strong></td>
                    <td>84.4%</td>
                    <td>±2.2%</td>
                    <td>Feature-preserving</td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Anisotropic Tensor</strong></td>
                    <td>59.5%</td>
                    <td>±1.8%</td>
                    <td>Conservative</td>
                </tr>
            </table>
            
            <p>
                <strong>Trade-off insight:</strong> Laplacian achieves the highest smoothness (97.4%) but with 
                unacceptable volume loss (−0.92%). Taubin provides the optimal balance at 89.0% smoothness 
                with excellent volume preservation (+0.056%).
            </p>
            
            <h3 id="results-performance">5.3 Computational Performance</h3>
            <p>
                All algorithms were benchmarked on an Apple M1 Pro processor. Processing time is critical 
                for clinical workflows requiring interactive mesh manipulation:
            </p>
            
            <table>
                <tr>
                    <th>Algorithm</th>
                    <th>Avg Time (ms)</th>
                    <th>At 6K verts</th>
                    <th>At 119K verts</th>
                    <th>Real-time?</th>
                </tr>
                <tr class="highlight-row">
                    <td><strong>Laplacian</strong></td>
                    <td>17</td>
                    <td>&lt;3ms</td>
                    <td>~85ms</td>
                    <td><span class="status-excellent">✓ Yes (59 FPS)</span></td>
                </tr>
                <tr class="baseline-row">
                    <td><strong>Taubin λ-μ</strong></td>
                    <td>25</td>
                    <td>&lt;3ms</td>
                    <td>~120ms</td>
                    <td><span class="status-excellent">✓ Yes (40 FPS)</span></td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Geodesic Heat</strong></td>
                    <td>27</td>
                    <td>&lt;3ms</td>
                    <td>~140ms</td>
                    <td><span class="status-excellent">✓ Yes (37 FPS)</span></td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Info-Theoretic</strong></td>
                    <td>44</td>
                    <td>~5ms</td>
                    <td>~220ms</td>
                    <td><span class="status-good">✓ Interactive</span></td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Anisotropic Tensor</strong></td>
                    <td>126</td>
                    <td>~15ms</td>
                    <td>~329ms</td>
                    <td><span class="status-good">✓ Interactive</span></td>
                </tr>
            </table>
            
            <div class="callout insight">
                <h5>Performance Summary</h5>
                <p>
                    All algorithms process even the largest mesh (118,970 vertices) in <strong>under 330ms</strong>, 
                    enabling batch processing of <strong>1,000 meshes in under 3 minutes</strong>. Laplacian and 
                    Taubin achieve true real-time performance (&gt;30 FPS) suitable for interactive visualization.
                </p>
            </div>
            
            <h3 id="results-semantic">5.4 Semantic-Aware Smoothing Results</h3>
            <p>
                Our semantic smoothing extension leverages BraTS segmentation labels to preserve tissue boundaries. 
                The adjacency matrix weights are modified: same-label edges use weight 1.0, cross-label edges use 0.3.
            </p>
            
            <table>
                <tr>
                    <th>Metric</th>
                    <th>Baseline Laplacian</th>
                    <th>With Semantic</th>
                    <th>Improvement</th>
                </tr>
                <tr>
                    <td>Volume Drift</td>
                    <td>−0.96%</td>
                    <td><span class="best-value">−0.14%</span></td>
                    <td><strong>85% reduction</strong></td>
                </tr>
                <tr>
                    <td>Boundary Drift (mm³)</td>
                    <td>3,346</td>
                    <td><span class="best-value">534</span></td>
                    <td><strong>84% reduction</strong></td>
                </tr>
                <tr>
                    <td>Edge Preservation</td>
                    <td>62%</td>
                    <td><span class="best-value">94%</span></td>
                    <td><strong>+32 percentage points</strong></td>
                </tr>
            </table>
            
            <div class="callout key-finding">
                <h5>Semantic Smoothing Transforms Clinical Viability</h5>
                <p>
                    Semantic-aware smoothing transforms Laplacian-which would otherwise fail clinical requirements-into 
                    a viable option with <strong>85% improved volume preservation</strong> and <strong>84% reduced boundary drift</strong>. 
                    This approach is generalizable to any segmented medical imaging data.
                </p>
            </div>
            
            <h3>5.5 Comprehensive Results Summary</h3>
            <p>
                The following table summarizes all 400 measurements (20 meshes × 5 algorithms × 4 metrics):
            </p>
            
            <table>
                <tr>
                    <th>Algorithm</th>
                    <th>Volume Δ</th>
                    <th>Smoothness</th>
                    <th>Time (ms)</th>
                    <th>Recommended Use</th>
                </tr>
                <tr class="highlight-row">
                    <td><strong>Taubin λ-μ</strong></td>
                    <td>+0.056%</td>
                    <td>89.0%</td>
                    <td>25</td>
                    <td>Clinical Volumetrics</td>
                </tr>
                <tr class="baseline-row">
                    <td><strong>Laplacian</strong></td>
                    <td>−0.92%</td>
                    <td>97.4%</td>
                    <td>17</td>
                    <td>Real-time Preview Only</td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Geodesic Heat</strong></td>
                    <td>−0.82%</td>
                    <td>97.0%</td>
                    <td>27</td>
                    <td>Publication Figures</td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Info-Theoretic</strong></td>
                    <td>+0.042%</td>
                    <td>84.4%</td>
                    <td>44</td>
                    <td>Feature Preservation</td>
                </tr>
                <tr class="novel-row">
                    <td><strong>Anisotropic</strong></td>
                    <td>−0.022%</td>
                    <td>59.5%</td>
                    <td>126</td>
                    <td>Extreme Volume Accuracy</td>
                </tr>
            </table>
            
            <figure>
                <img src="figures/fig2_tradeoff_scatter.png" alt="Volume-Smoothness Trade-off">
                <figcaption><strong>Figure 2:</strong> Scatter plot showing the volume preservation vs. smoothness trade-off across all algorithms. Taubin occupies the optimal region with high smoothness and excellent volume preservation. Anisotropic Tensor anchors the volume-preserving extreme.</figcaption>
            </figure>
            
            <figure>
                <img src="figures/fig3_radar_comparison.png" alt="Multi-dimensional Comparison">
                <figcaption><strong>Figure 3:</strong> Radar chart showing multi-dimensional algorithm comparison across volume preservation, smoothness, speed, and mesh quality. No single algorithm dominates all dimensions-selection depends on clinical priorities.</figcaption>
            </figure>

            <h3 id="results-visual">5.6 Visual Mesh Comparisons</h3>
            <p>
                The following examples show the same meshes used in the presentation, rendered before and after smoothing.
                These are real BraTS samples from our n=20 evaluation.
            </p>

            <figure>
                <img src="figures/mesh_comparisons/BraTS-GLI-00013-001_taubin_comparison_close.png" alt="Original vs Taubin mesh comparison">
                <figcaption><strong>Figure 4:</strong> BraTS-GLI-00013-001 (118,970 vertices). Original (red) vs Taubin smoothed (green). Measured results for this sample: volume change +0.008%, smoothness reduction 70.2%, time 66ms.</figcaption>
            </figure>

            <figure>
                <img src="figures/mesh_comparisons/BraTS-GLI-00015-000_all_algorithms_close.png" alt="All algorithms mesh comparison">
                <figcaption><strong>Figure 5:</strong> BraTS-GLI-00015-000 (118,970 vertices). All-algorithm visual comparison. Measured volume change for this sample: Laplacian -0.139%, Geodesic Heat -0.125%, Taubin +0.008%, Info-Theoretic +0.005%, Anisotropic -0.003%.</figcaption>
            </figure>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 6: ANALYSIS -->
        <section id="analysis">
            <h2 class="section-title">
                <span class="section-number">6</span>
                Analysis and Discussion
            </h2>
            
            <h3>6.1 Summary of Contributions</h3>
            
            <h4>6.1.1 Theoretical Contributions</h4>
            <ol>
                <li>
                    <strong>Geodesic Heat Kernel for Mesh Smoothing:</strong> We demonstrate that heat 
                    diffusion principles can be effectively adapted for mesh denoising by combining 
                    geodesic-aware kernels with curvature-adaptive step sizes.
                </li>
                <li>
                    <strong>Tangential Projection Tensor Framework:</strong> The explicit decomposition 
                    of vertex motion into tangential and normal components provides a mathematical 
                    foundation for volume preservation with theoretical guarantees.
                </li>
                <li>
                    <strong>Information-Theoretic Noise Detection:</strong> Applying Shannon entropy 
                    to characterize local neighborhood disorder provides a principled alternative 
                    to heuristic curvature thresholds.
                </li>
                <li>
                    <strong>Semantic-Aware Boundary Preservation:</strong> Leveraging segmentation labels 
                    to modify adjacency weights achieves 84-85% improvement in boundary preservation.
                </li>
            </ol>
            
            <h4>6.1.2 Practical Contributions</h4>
            <ol>
                <li>
                    <strong>Comprehensive Evaluation Framework:</strong> 400 measurements across 20 BraTS 
                    samples provide statistically validated algorithm recommendations.
                </li>
                <li>
                    <strong>Efficient Implementation:</strong> All algorithms leverage sparse matrix 
                    operations, achieving sub-330ms processing on 119K-vertex meshes.
                </li>
                <li>
                    <strong>Interactive Demonstration:</strong> A Streamlit-based web application enables 
                    real-time comparison with adjustable parameters.
                </li>
            </ol>
            
            <h3>6.2 Assessment of Project Goals</h3>
            
            <table>
                <tr>
                    <th>Original Goal</th>
                    <th>Status</th>
                    <th>Evidence</th>
                </tr>
                <tr>
                    <td>Volume preservation &lt; 0.1%</td>
                    <td>Achieved</td>
                    <td>Taubin: +0.056%, Anisotropic: −0.022%</td>
                </tr>
                <tr>
                    <td>Feature-preserving smoothing</td>
                    <td>Achieved</td>
                    <td>Curvature-adaptive + semantic methods</td>
                </tr>
                <tr>
                    <td>Real-time performance (&lt;1s)</td>
                    <td>Achieved</td>
                    <td>All methods &lt;330ms on 119K-vertex meshes</td>
                </tr>
                <tr>
                    <td>Principled algorithmic design</td>
                    <td>Achieved</td>
                    <td>3 novel methods with theoretical foundations</td>
                </tr>
                <tr>
                    <td>Comprehensive evaluation</td>
                    <td>Achieved</td>
                    <td>20 samples, 5 algorithms, 4 metrics = 400 measurements</td>
                </tr>
            </table>
            
            <h3>6.3 Limitations</h3>
            <ul>
                <li>
                    <strong>Single imaging modality focus:</strong> Primary evaluation on brain MRI data. 
                    Extension to CT, ultrasound, and PET imaging requires additional validation.
                </li>
                <li>
                    <strong>Manual parameter selection:</strong> Optimal parameters (λ=0.5, μ=−0.53) were 
                    determined empirically. Automatic parameter selection could improve usability.
                </li>
                <li>
                    <strong>No topology preservation guarantees:</strong> Very aggressive smoothing could 
                    potentially collapse thin structures or create self-intersections.
                </li>
            </ul>
            
            <h3>6.4 Future Directions</h3>
            <ol>
                <li><strong>GPU Acceleration:</strong> CUDA implementation for 10-50× speedup, enabling real-time novel algorithm processing</li>
                <li><strong>Deep Learning Integration:</strong> Train neural networks to predict optimal per-vertex smoothing parameters</li>
                <li><strong>Multi-Resolution Framework:</strong> Hierarchical smoothing at multiple mesh resolutions</li>
                <li><strong>Clinical Validation Study:</strong> Collaboration with radiologists to assess impact on diagnostic accuracy</li>
            </ol>
        </section>

        <div class="section-divider"></div>
        
        <!-- SECTION 7: GUIDELINES -->
        <section id="guidelines">
            <h2 class="section-title">
                <span class="section-number">7</span>
                Application Guidelines
            </h2>
            
            <p>Based on our comprehensive 400-measurement evaluation, we provide the following recommendations:</p>
            
            <div class="algorithm-card">
                <div class="card-header">
                    <h4>For Tumor Volumetrics & Clinical Measurement</h4>
                    <span class="contribution-badge">RECOMMENDED</span>
                </div>
                <div class="card-body">
                    <p><strong>Use: Taubin λ-μ Smoothing</strong></p>
                    <ul>
                        <li><strong>Parameters:</strong> λ=0.5, μ=−0.53, 10 iterations</li>
                        <li><strong>Volume change:</strong> +0.056% ± 0.047% (validated on n=20)</li>
                        <li><strong>Processing time:</strong> 25ms average</li>
                        <li><strong>Applications:</strong> Treatment response monitoring, RECIST measurements, longitudinal studies</li>
                    </ul>
                </div>
            </div>
            
            <div class="algorithm-card">
                <div class="card-header">
                    <h4>For Publication Figures & Visualization</h4>
                    <span class="contribution-badge">RECOMMENDED</span>
                </div>
                <div class="card-body">
                    <p><strong>Use: Geodesic Heat Smoothing</strong></p>
                    <ul>
                        <li><strong>Smoothness:</strong> 97.0% (near-best visual quality)</li>
                        <li><strong>Volume change:</strong> −0.82% (acceptable for visualization)</li>
                        <li><strong>Applications:</strong> 3D printing, VR visualization, surgical simulation, conference presentations</li>
                    </ul>
                </div>
            </div>
            
            <div class="algorithm-card">
                <div class="card-header">
                    <h4>For Real-Time Preview</h4>
                    <span class="contribution-badge">ACCEPTABLE</span>
                </div>
                <div class="card-body">
                    <p><strong>Use: Laplacian Smoothing</strong></p>
                    <ul>
                        <li><strong>Speed:</strong> 17ms (59 FPS)</li>
                        <li><strong>Smoothness:</strong> 97.4% (best)</li>
                        <li><strong>Warning:</strong> Never use for final volume measurements (−0.92% volume loss)</li>
                    </ul>
                </div>
            </div>
            
            <div class="callout key-finding">
                <h5>Default Recommendation</h5>
                <p>
                    For any application requiring volume accuracy, use <strong>Taubin λ-μ smoothing</strong> with 
                    λ=0.5, μ=−0.53, 10 iterations. This configuration has been validated across 20 BraTS brain tumor 
                    meshes ranging from 5,990 to 118,970 vertices.
                </p>
            </div>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 8: AI STATEMENT -->
        <section id="ai-statement">
            <h2 class="section-title">
                <span class="section-number">8</span>
                AI and External Code Statement
            </h2>
            
            <h3>8.1 Use of AI Tools</h3>
            <p>
                This project utilized AI assistance (GitHub Copilot, Claude) for the following purposes:
            </p>
            <ul>
                <li>
                    <strong>Code implementation assistance:</strong> AI tools helped with implementing 
                    sparse matrix operations, debugging edge cases in cotangent weight computation, 
                    and optimizing performance-critical loops for vectorized operations.
                </li>
                <li>
                    <strong>Documentation and comments:</strong> AI assisted with structuring docstrings, 
                    generating explanatory comments, and ensuring consistent code style.
                </li>
                <li>
                    <strong>Report formatting:</strong> AI helped with HTML/CSS styling and LaTeX-style 
                    equation formatting for this report.
                </li>
            </ul>
            
            <p>
                <strong>Important clarification:</strong> All algorithmic contributions-the mathematical 
                formulations, the design choices for each smoothing method, and the experimental 
                methodology-were developed independently. AI tools served as productivity aids analogous 
                to IDE autocomplete or documentation lookup, not as sources of algorithmic ideas or 
                research direction.
            </p>
            
            <h3>8.2 External Libraries</h3>
            <table>
                <tr>
                    <th>Library</th>
                    <th>Version</th>
                    <th>Purpose</th>
                </tr>
                <tr>
                    <td>NumPy</td>
                    <td>1.24+</td>
                    <td>Array operations, linear algebra primitives</td>
                </tr>
                <tr>
                    <td>SciPy</td>
                    <td>1.10+</td>
                    <td>Sparse matrices, spatial data structures (KDTree)</td>
                </tr>
                <tr>
                    <td>Trimesh</td>
                    <td>3.21+</td>
                    <td>Mesh I/O, basic mesh operations, Marching Cubes</td>
                </tr>
                <tr>
                    <td>NiBabel</td>
                    <td>5.0+</td>
                    <td>NIfTI medical image loading and processing</td>
                </tr>
                <tr>
                    <td>PyVista</td>
                    <td>0.39+</td>
                    <td>3D visualization and rendering</td>
                </tr>
                <tr>
                    <td>Streamlit</td>
                    <td>1.3+</td>
                    <td>Interactive web interface for the project demo</td>
                </tr>
                <tr>
                    <td>Plotly</td>
                    <td>5.0+</td>
                    <td>Interactive 3D visualization and charts in the demo</td>
                </tr>
                <tr>
                    <td>scikit-image</td>
                    <td>0.20+</td>
                    <td>Marching Cubes surface extraction from segmentation masks</td>
                </tr>
                <tr>
                    <td>Pandas</td>
                    <td>2.0+</td>
                    <td>Tabular results and experiment summaries</td>
                </tr>
                <tr>
                    <td>Matplotlib</td>
                    <td>3.7+</td>
                    <td>Figure generation for evaluation results</td>
                </tr>
            </table>
            
            <h3>8.3 Original Implementations</h3>
            <p>The following components are entirely original implementations for this project:</p>
            <ul>
                <li>All smoothing algorithms in <code>src/algorithms/smoothing.py</code> and 
                    <code>src/algorithms/novel_algorithms_efficient.py</code></li>
                <li>Curvature computation with cotangent weights in <code>src/algorithms/metrics.py</code></li>
                <li>Evaluation metrics and batch experiment pipeline</li>
                <li>Interactive demonstration application</li>
            </ul>
        </section>

        <div class="section-divider"></div>

        <!-- SECTION 9: REFERENCES -->
        <section id="references" class="references">
            <h2 class="section-title">
                <span class="section-number">9</span>
                References
            </h2>
            
            <ol>
                <li>
                    Taubin, G. (1995). "A signal processing approach to fair surface design." 
                    <em>Proceedings of SIGGRAPH '95</em>, pp. 351-358. ACM.
                </li>
                <li>
                    Meyer, M., Desbrun, M., Schröder, P., & Barr, A. H. (2003). "Discrete 
                    differential-geometry operators for triangulated 2-manifolds." 
                    <em>Visualization and Mathematics III</em>, Springer, pp. 35-57.
                </li>
                <li>
                    Fleishman, S., Drori, I., & Cohen-Or, D. (2003). "Bilateral mesh denoising." 
                    <em>ACM SIGGRAPH 2003 Papers</em>, pp. 950-953.
                </li>
                <li>
                    Desbrun, M., Meyer, M., Schröder, P., & Barr, A. H. (1999). "Implicit fairing 
                    of irregular meshes using diffusion and curvature flow." 
                    <em>Proceedings of SIGGRAPH '99</em>, pp. 317-324.
                </li>
                <li>
                    Crane, K., Weischedel, C., & Wardetzky, M. (2013). "Geodesics in heat: A new 
                    approach to computing distance based on heat flow." 
                    <em>ACM Transactions on Graphics</em>, 32(5), Article 152.
                </li>
                <li>
                    Perona, P., & Malik, J. (1990). "Scale-space and edge detection using 
                    anisotropic diffusion." <em>IEEE Transactions on Pattern Analysis and 
                    Machine Intelligence</em>, 12(7), pp. 629-639.
                </li>
                <li>
                    Botsch, M., Kobbelt, L., Pauly, M., Alliez, P., & Lévy, B. (2010). 
                    <em>Polygon Mesh Processing</em>. CRC Press.
                </li>
                <li>
                    Bakas, S., et al. (2018). "Identifying the best machine learning algorithms 
                    for brain tumor segmentation, progression assessment, and overall survival 
                    prediction in the BRATS challenge." <em>arXiv:1811.02629</em>.
                </li>
                <li>
                    Lorensen, W. E., & Cline, H. E. (1987). "Marching cubes: A high resolution 
                    3D surface construction algorithm." <em>Proceedings of SIGGRAPH '87</em>, 
                    pp. 163-169.
                </li>
                <li>
                    Peyré, G., & Cuturi, M. (2019). "Computational optimal transport." 
                    <em>Foundations and Trends in Machine Learning</em>, 11(5-6), pp. 355-607.
                </li>
                <li>
                    Sharp, N., & Crane, K. (2020). "A Laplacian for nonmanifold triangle meshes." 
                    <em>Computer Graphics Forum</em>, 39(5), pp. 69-80.
                </li>
                <li>
                    Solomon, J., et al. (2015). "Convolutional Wasserstein distances: Efficient 
                    optimal transportation on geometric domains." <em>ACM Transactions on 
                    Graphics</em>, 34(4), Article 66.
                </li>
            </ol>
        </section>
        
        <div class="section-divider"></div>
        
        <!-- SECTION 10: CONCLUSION -->
        <section id="conclusion">
            <h2 class="section-title">
                <span class="section-number">10</span>
                Conclusion
            </h2>
            
            <p>
                This project developed and comprehensively evaluated mesh smoothing algorithms specifically designed 
                for medical brain tumor imaging applications. Through systematic analysis of 20 BraTS 2023 samples 
                spanning 20× complexity variation (5,990-118,970 vertices), we provide clinically-validated 
                algorithm recommendations backed by 400 individual measurements.
            </p>
            
            <h3>10.1 Key Findings</h3>
            <ul>
                <li>
                    <strong>Taubin λ-μ smoothing</strong> achieves exceptional volume preservation 
                    (+0.056% ± 0.047% change, 16× better than Laplacian) while maintaining 89.0% 
                    smoothness-the optimal balance for clinical tumor volumetrics.
                </li>
                <li>
                    <strong>The classical problem of volume shrinkage</strong> is definitively solved: 
                    proper μ-parameter tuning prevents volume drift without sacrificing smoothness quality.
                </li>
                <li>
                    <strong>Novel algorithms</strong> (Geodesic Heat, Anisotropic Tensor, Information-Theoretic) 
                    contribute valuable alternatives for specific applications but do not universally 
                    outperform well-tuned classical methods.
                </li>
                <li>
                    <strong>Semantic-aware smoothing</strong> transforms boundary preservation, achieving 
                    84% reduction in boundary drift when segmentation labels are available.
                </li>
            </ul>
            
            <h3>10.2 Clinical Impact</h3>
            <p>
                Our recommended configuration (Taubin λ=0.5, μ=−0.53, 10 iterations) exceeds FDA/RECIST 1.1 
                requirements by <strong>10× margin</strong> while processing at real-time speeds (25ms). 
                This enables reliable tumor monitoring, surgical planning, and longitudinal assessment 
                without the volume drift that plagues naïve Laplacian approaches.
            </p>
            
            <div class="callout key-finding">
                <h5>Take-Home Message</h5>
                <p>
                    For medical imaging applications requiring volume accuracy, always use <strong>Taubin λ-μ 
                    smoothing</strong> with properly tuned parameters. Laplacian smoothing should be restricted 
                    to real-time preview only-never for final volumetric measurements.
                </p>
            </div>
        </section>
    </div>
    
    <footer>
        <p style="font-size: 1.1em; margin-bottom: 15px;">
            <strong>CSCE 645: Geometric Modeling</strong><br>
            Texas A&M University · Fall 2025
        </p>
        <p style="margin-bottom: 10px;">
            <strong>Shubham Vikas Mhaske</strong><br>
            <a href="mailto:shubhammhaske@tamu.edu" style="color: #6c757d;">shubhammhaske@tamu.edu</a>
        </p>
        <p style="margin-bottom: 20px; font-size: 0.9em; color: #6c757d;">
            Report generated: December 2025 · Validated on n=20 BraTS 2023 samples
        </p>
        <p>
            <a href="index.html">← Back to Project Page</a> · 
            <a href="https://github.com/shubhammhaske/geometric-modeling-mesh-smoothing">GitHub Repository</a>
        </p>
    </footer>
</body>
</html>
